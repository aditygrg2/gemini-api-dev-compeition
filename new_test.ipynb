{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import google.generativeai as genai\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.agents import AgentExecutor, create_json_chat_agent\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from vertexai.generative_models import (\n",
    "    SafetySetting,\n",
    "    HarmCategory,\n",
    "    HarmBlockThreshold,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "def convert_to_str(messages):\n",
    "    ans = \"\"\n",
    "    for i in messages:\n",
    "        ans += i[0] + \" : \" + i[1] + \"\\n\"\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety = [\n",
    "    SafetySetting(\n",
    "        category=HarmCategory.HARM_CATEGORY_UNSPECIFIED,\n",
    "        threshold=HarmBlockThreshold.BLOCK_NONE\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=HarmBlockThreshold.BLOCK_NONE\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold=HarmBlockThreshold.BLOCK_NONE\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        threshold=HarmBlockThreshold.BLOCK_NONE\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold=HarmBlockThreshold.BLOCK_NONE\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\",\n",
    "    client=genai,\n",
    "    temperature=0.5,\n",
    "    safety_settings=None\n",
    ")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "        model=\"models/embedding-001\")\n",
    "\n",
    "new_db = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "user_data = \"\"\"\n",
    "  \n",
    "    ```\n",
    "       [{\n",
    "  \"phone_no\": 932489237,\n",
    "  \"name\": \"Raj Patel\",\n",
    "  \"address\": {\n",
    "  \"apartment_no\": \"223, Suryasthali Appartment\",\n",
    "  \"area_street\": \"Manavta Nagar\",\n",
    "  \"landmark\": \"Hanuman Mandir\",\n",
    "  \"town_city\": \"Bengaluru\",\n",
    "  \"state\": \"Karnataka\",\n",
    "  \"pincode\": 530068\n",
    "  },\n",
    "  \"email\": \"raja23@gmail.com\",\n",
    "  \"subscriptionStatus\": false,\n",
    "  \"previousOrders\": [\n",
    "    {\n",
    "  \"order_id\": “20234435843-1107”,\n",
    "  \"status\": \"Delivered\",\n",
    "  \"transaction\": {\n",
    "  \"transaction_id\": \"txn123dsafasd\",\n",
    "  \"status\": \"Successful\",\n",
    "  \"payment_method\": \"Amazon Pay\",\n",
    "  \"total_amount\": 3000,\n",
    "  \"timestamp\": {\n",
    "    \"$date\": \"2024-06-14T18:55:34.443Z\"\n",
    "  }\n",
    "  },\n",
    "  \"items\": [\n",
    "  \"product_id\": 3247387,\n",
    "  \"name\": \"HRX Oversized T-Shirt\",\n",
    "  \"description\": \"Cotton-Comfy fit Oversized T-Shirt\",\n",
    "  \"category\": \"Clothing-Men-TShirt\",\n",
    "  \"average_rating\": 3,\n",
    "  \"price\": 399,\n",
    "  \"reviews\": [\n",
    "    \"Very Comfortable and Affordable\",\n",
    "    \"Cheap and affordable\",\n",
    "    \"Don't BUY AT ALLLL\"\n",
    "  ]\n",
    "  ],\n",
    "    ```\n",
    "\"\"\"\n",
    "\n",
    "first_context = \"\"\"\n",
    "    Your name is Radhika from Amazon Customer Support Agent Team and you will be helping a customer today. \n",
    "\n",
    "    You will be speaking, so output text accordingly. \n",
    "\n",
    "    Do not verify anything about user because he is already verified.\n",
    "\n",
    "    You can ask user if you need any details.\n",
    "    \n",
    "    You should never ask them to contact Amazon Customer service, instead if you are unable to find the answer, forward the call to agent and terminate by [AGENT]\n",
    "\"\"\"\n",
    "\n",
    "initial_prompt_template = \"\"\"\n",
    "    {first_context}\n",
    "\n",
    "    {context}\n",
    "\n",
    "    User Question: \n",
    "    Only try to answer this and add nothing else.\n",
    "    {user_input}\n",
    "\n",
    "    User Data:\n",
    "    Only relevant to queries which needs user data to be checked!\n",
    "    {user_data}\n",
    "\n",
    "    Previous Chat History:\n",
    "    While thinking of answer, go through the conversation to get the context of what user mean, but answer only according to User Question\n",
    "    {chat_history}\n",
    "\n",
    "    WRITE [TERMINATE] IF THE USER IS SATISFIED\n",
    "    IF UNABLE TO FIND THE USER ANSWER IN CONTEXT, TRANSFER THE CALL TO AGENT BY [AGENT]\n",
    "\n",
    "    {ending_lines}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"user_input\", \"first_context\", \"user_data\", \"ending_lines\", \"chat_history\"],\n",
    "    template=initial_prompt_template\n",
    ")\n",
    "\n",
    "chain = load_qa_chain(llm=model, chain_type=\"stuff\", prompt = prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chat_template = \"\"\"\n",
    "    Your name is Radhika from Amazon Customer Support Agent Team and you will be helping a customer today. \n",
    "    You will be speaking, so output text accordingly. \n",
    "    Do not verify anything about user because he is already verified.\n",
    "\n",
    "    You can ask user if you need any details.\n",
    "    \n",
    "    {tools}\n",
    "    {tool_names}\n",
    "    {agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "new_prompt = PromptTemplate(\n",
    "    input_variables=[\"tools\", \"tool_names\", \"agent_scratchpad\"],\n",
    "    template=new_chat_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: Hi there, my name is Radhika. I'm from Amazon Customer Support. How can I help you today?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/agents/output_parsers/json.py:45\u001b[0m, in \u001b[0;36mJSONAgentOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     response \u001b[39m=\u001b[39m parse_json_markdown(text)\n\u001b[1;32m     46\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(response, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     47\u001b[0m         \u001b[39m# gpt turbo frequently ignores the directive to emit a single action\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/utils/json.py:147\u001b[0m, in \u001b[0;36mparse_json_markdown\u001b[0;34m(json_string, parser)\u001b[0m\n\u001b[1;32m    146\u001b[0m         json_str \u001b[39m=\u001b[39m match\u001b[39m.\u001b[39mgroup(\u001b[39m2\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m \u001b[39mreturn\u001b[39;00m _parse_json(json_str, parser\u001b[39m=\u001b[39;49mparser)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/utils/json.py:160\u001b[0m, in \u001b[0;36m_parse_json\u001b[0;34m(json_str, parser)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m \u001b[39mreturn\u001b[39;00m parser(json_str)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/utils/json.py:120\u001b[0m, in \u001b[0;36mparse_partial_json\u001b[0;34m(s, strict)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m# for the original string.\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39;49mloads(s, strict\u001b[39m=\u001b[39;49mstrict)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m     kw[\u001b[39m'\u001b[39m\u001b[39mparse_constant\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\u001b[39m.\u001b[39;49mdecode(s)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/agents/agent.py:1167\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1167\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mplan(\n\u001b[1;32m   1168\u001b[0m         intermediate_steps,\n\u001b[1;32m   1169\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1170\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs,\n\u001b[1;32m   1171\u001b[0m     )\n\u001b[1;32m   1172\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/agents/agent.py:398\u001b[0m, in \u001b[0;36mRunnableAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_runnable:\n\u001b[1;32m    392\u001b[0m     \u001b[39m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     \u001b[39m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[39m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[39m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunnable\u001b[39m.\u001b[39mstream(inputs, config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}):\n\u001b[1;32m    399\u001b[0m         \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:2882\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2876\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstream\u001b[39m(\n\u001b[1;32m   2877\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2878\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   2879\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2880\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2881\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 2882\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(\u001b[39miter\u001b[39m([\u001b[39minput\u001b[39m]), config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:2869\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2863\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\n\u001b[1;32m   2864\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2865\u001b[0m     \u001b[39minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   2866\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2867\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2868\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 2869\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   2870\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   2871\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform,\n\u001b[1;32m   2872\u001b[0m         patch_config(config, run_name\u001b[39m=\u001b[39m(config \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname),\n\u001b[1;32m   2873\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2874\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:1867\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1866\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1867\u001b[0m     chunk: Output \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mrun(\u001b[39mnext\u001b[39m, iterator)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m     \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:2831\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   2829\u001b[0m         final_pipeline \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39mtransform(final_pipeline, config)\n\u001b[0;32m-> 2831\u001b[0m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2832\u001b[0m     \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:1181\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream(final, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:816\u001b[0m, in \u001b[0;36mRunnable.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[39mDefault implementation of stream, which calls invoke.\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[39mSubclasses should override this method if they support streaming output.\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 816\u001b[0m \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minvoke(\u001b[39minput\u001b[39;49m, config, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:169\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39minput\u001b[39m, BaseMessage):\n\u001b[0;32m--> 169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_with_config(\n\u001b[1;32m    170\u001b[0m         \u001b[39mlambda\u001b[39;49;00m inner_input: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_result(\n\u001b[1;32m    171\u001b[0m             [ChatGeneration(message\u001b[39m=\u001b[39;49minner_input)]\n\u001b[1;32m    172\u001b[0m         ),\n\u001b[1;32m    173\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    174\u001b[0m         config,\n\u001b[1;32m    175\u001b[0m         run_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mparser\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:1598\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1595\u001b[0m     context\u001b[39m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1596\u001b[0m     output \u001b[39m=\u001b[39m cast(\n\u001b[1;32m   1597\u001b[0m         Output,\n\u001b[0;32m-> 1598\u001b[0m         context\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m   1599\u001b[0m             call_func_with_variable_args,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1600\u001b[0m             func,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1601\u001b[0m             \u001b[39minput\u001b[39;49m,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1602\u001b[0m             config,\n\u001b[1;32m   1603\u001b[0m             run_manager,\n\u001b[1;32m   1604\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1605\u001b[0m         ),\n\u001b[1;32m   1606\u001b[0m     )\n\u001b[1;32m   1607\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/runnables/config.py:380\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 380\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:170\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39minput\u001b[39m, BaseMessage):\n\u001b[1;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_with_config(\n\u001b[0;32m--> 170\u001b[0m         \u001b[39mlambda\u001b[39;00m inner_input: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_result(\n\u001b[1;32m    171\u001b[0m             [ChatGeneration(message\u001b[39m=\u001b[39;49minner_input)]\n\u001b[1;32m    172\u001b[0m         ),\n\u001b[1;32m    173\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m    174\u001b[0m         config,\n\u001b[1;32m    175\u001b[0m         run_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparser\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:221\u001b[0m, in \u001b[0;36mBaseOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \n\u001b[1;32m    211\u001b[0m \u001b[39mThe return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39m    Structured output.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse(result[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mtext)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/agents/output_parsers/json.py:57\u001b[0m, in \u001b[0;36mJSONAgentOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not parse LLM output: \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Could not parse LLM output: Hi there, my name is Radhika. I'm from Amazon Customer Support. How can I help you today?",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[816], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m agent \u001b[38;5;241m=\u001b[39m create_json_chat_agent(model, tools\u001b[38;5;241m=\u001b[39mnew_tools, prompt\u001b[38;5;241m=\u001b[39mnew_prompt)\n\u001b[1;32m      2\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m AgentExecutor\u001b[38;5;241m.\u001b[39mfrom_agent_and_tools(agent \u001b[38;5;241m=\u001b[39m agent, tools\u001b[38;5;241m=\u001b[39mnew_tools) \u001b[38;5;66;03m# Add this line.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThank you for the help!\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/chains/base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    167\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    169\u001b[0m \u001b[39mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/chains/base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    155\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 156\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    157\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    158\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    161\u001b[0m     final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/agents/agent.py:1433\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1433\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[1;32m   1434\u001b[0m         name_to_tool_map,\n\u001b[1;32m   1435\u001b[0m         color_mapping,\n\u001b[1;32m   1436\u001b[0m         inputs,\n\u001b[1;32m   1437\u001b[0m         intermediate_steps,\n\u001b[1;32m   1438\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m   1439\u001b[0m     )\n\u001b[1;32m   1440\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1441\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[1;32m   1442\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[1;32m   1443\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/agents/agent.py:1139\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_next_step\u001b[39m(\n\u001b[1;32m   1131\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1132\u001b[0m     name_to_tool_map: Dict[\u001b[39mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1137\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[39mstr\u001b[39m]]]:\n\u001b[1;32m   1138\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1139\u001b[0m         [\n\u001b[1;32m   1140\u001b[0m             a\n\u001b[1;32m   1141\u001b[0m             \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iter_next_step(\n\u001b[1;32m   1142\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1143\u001b[0m                 color_mapping,\n\u001b[1;32m   1144\u001b[0m                 inputs,\n\u001b[1;32m   1145\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1146\u001b[0m                 run_manager,\n\u001b[1;32m   1147\u001b[0m             )\n\u001b[1;32m   1148\u001b[0m         ]\n\u001b[1;32m   1149\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/agents/agent.py:1139\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_next_step\u001b[39m(\n\u001b[1;32m   1131\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1132\u001b[0m     name_to_tool_map: Dict[\u001b[39mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1137\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[39mstr\u001b[39m]]]:\n\u001b[1;32m   1138\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1139\u001b[0m         [\n\u001b[1;32m   1140\u001b[0m             a\n\u001b[1;32m   1141\u001b[0m             \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1142\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1143\u001b[0m                 color_mapping,\n\u001b[1;32m   1144\u001b[0m                 inputs,\n\u001b[1;32m   1145\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1146\u001b[0m                 run_manager,\n\u001b[1;32m   1147\u001b[0m             )\n\u001b[1;32m   1148\u001b[0m         ]\n\u001b[1;32m   1149\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/agents/agent.py:1178\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     raise_error \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[39mif\u001b[39;00m raise_error:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1179\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn output parsing error occurred. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1180\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1182\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis is the error: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1183\u001b[0m     )\n\u001b[1;32m   1184\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[1;32m   1185\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: Hi there, my name is Radhika. I'm from Amazon Customer Support. How can I help you today?"
     ]
    }
   ],
   "source": [
    "agent = create_json_chat_agent(model, tools=new_tools, prompt=new_prompt)\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent = agent, tools=new_tools) # Add this line.\n",
    "\n",
    "agent_executor.invoke({\"input\": \"Thank you for the help!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_contexts(term):\n",
    "    contexts = new_db.similarity_search_with_score(term, k=3)\n",
    "\n",
    "    ans_contexts = []\n",
    "\n",
    "    for i in contexts:\n",
    "        print(i[1])\n",
    "        if(i[1] > 0.5):\n",
    "            ans_contexts.append(i[0])\n",
    "\n",
    "    return ans_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40284258\n",
      "0.4272114\n",
      "0.44770235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_text': 'I am sorry to hear that you received a damaged item. I can help you with that. May I know the order ID of the damaged item?'}"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First Input\n",
    "user_question = \" Hi, I received a damaged item and I’d like to request a refund.\"\n",
    "context_user = filter_contexts(user_question)\n",
    "\n",
    "first_message = initial_prompt_template.format(first_context = first_context, input_documents = context_user, user_input = user_question, user_data = user_data, ending_lines = \"Your call is now live with the agent! Do not include anything of previous chat in replies. Use them to only generate future answers.\", context = '', chat_history = '')\n",
    "\n",
    "res = chain({\n",
    "    \"first_context\": first_context, \n",
    "    \"input_documents\": context_user, \n",
    "    \"user_input\":  user_question, \n",
    "    \"user_data\": \"User Data \\n\" + user_data, \n",
    "    \"ending_lines\": \"Begin! Call is live with customer\", \n",
    "    \"chat_history\": convert_to_str(messages)\n",
    "}, return_only_outputs=True)\n",
    "\n",
    "messages.append((\"system\", first_message))\n",
    "messages.append((\"agent\", res['output_text']))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('system',\n",
       "  '\\n    \\n    Your name is Radhika from Amazon Customer Support Agent Team and you will be helping a customer today. \\n\\n    You will be speaking, so output text accordingly. \\n\\n    Do not verify anything about user because he is already verified.\\n\\n    You can ask user if you need any details.\\n    \\n    You should never ask them to contact Amazon Customer service, instead if you are unable to find the answer, forward the call to agent and terminate by [AGENT]\\n\\n\\n    \\n\\n    User Question: \\n    Only try to answer this and add nothing else.\\n     Hi, I received a damaged item and I’d like to request a refund.\\n\\n    User Data:\\n    Only relevant to queries which needs user data to be checked!\\n    \\n  \\n    ```\\n       [{\\n  \"phone_no\": 932489237,\\n  \"name\": \"Raj Patel\",\\n  \"address\": {\\n  \"apartment_no\": \"223, Suryasthali Appartment\",\\n  \"area_street\": \"Manavta Nagar\",\\n  \"landmark\": \"Hanuman Mandir\",\\n  \"town_city\": \"Bengaluru\",\\n  \"state\": \"Karnataka\",\\n  \"pincode\": 530068\\n  },\\n  \"email\": \"raja23@gmail.com\",\\n  \"subscriptionStatus\": false,\\n  \"previousOrders\": [\\n    {\\n  \"order_id\": “20234435843-1107”,\\n  \"status\": \"Delivered\",\\n  \"transaction\": {\\n  \"transaction_id\": \"txn123dsafasd\",\\n  \"status\": \"Successful\",\\n  \"payment_method\": \"Amazon Pay\",\\n  \"total_amount\": 3000,\\n  \"timestamp\": {\\n    \"$date\": \"2024-06-14T18:55:34.443Z\"\\n  }\\n  },\\n  \"items\": [\\n  \"product_id\": 3247387,\\n  \"name\": \"HRX Oversized T-Shirt\",\\n  \"description\": \"Cotton-Comfy fit Oversized T-Shirt\",\\n  \"category\": \"Clothing-Men-TShirt\",\\n  \"average_rating\": 3,\\n  \"price\": 399,\\n  \"reviews\": [\\n    \"Very Comfortable and Affordable\",\\n    \"Cheap and affordable\",\\n    \"Don\\'t BUY AT ALLLL\"\\n  ]\\n  ],\\n    ```\\n\\n\\n    Previous Chat History:\\n    While thinking of answer, go through the conversation to get the context of what user mean, but answer only according to User Question\\n    \\n\\n    WRITE [TERMINATE] IF THE USER IS SATISFIED\\n    IF UNABLE TO FIND THE USER ANSWER IN CONTEXT, TRANSFER THE CALL TO AGENT BY [AGENT]\\n\\n    Your call is now live with the agent! Do not include anything of previous chat in replies. Use them to only generate future answers.\\n'),\n",
       " ('agent',\n",
       "  'I am sorry to hear that you received a damaged item. I can help you with that. May I know the order ID of the damaged item?'),\n",
       " ('human',\n",
       "  'Sure, can you check the recent order. It is an HRX Oversized T-Shirt'),\n",
       " ('agent', '[AGENT]')]"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7050432\n",
      "0.71106863\n",
      "0.7267091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_text': '[AGENT]'}"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_question = \"Sure, can you check the recent order. It is an HRX Oversized T-Shirt\"\n",
    "context_user = filter_contexts(user_question)\n",
    "\n",
    "response = chain({\n",
    "    \"first_context\": \"\", \n",
    "    \"input_documents\": context_user, \n",
    "    \"user_input\": user_question, \n",
    "    \"user_data\": user_data, \n",
    "    \"ending_lines\": \"\", \n",
    "    \"chat_history\": convert_to_str(messages)\n",
    "}, return_only_outputs = True)\n",
    "\n",
    "messages.append((\"human\", user_question))\n",
    "messages.append((\"agent\", response['output_text']))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Okay, can you tell me something about me!\"\n",
    "context_user = new_db.similarity_search(user_question)\n",
    "\n",
    "response = chain({\n",
    "    \"first_context\": \"\",\n",
    "    \"input_documents\": \"\",\n",
    "    \"user_input\":  user_question,\n",
    "    \"user_data\": \"\", \"ending_lines\": \"\",\n",
    "    \"chat_history\": convert_to_str(messages)\n",
    "}, return_only_outputs = True)\n",
    "\n",
    "messages.append((\"human\", user_question))\n",
    "messages.append((\"agent\", response['output_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': '[TERMINATE]\\nThank you for calling Amazon!'}"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5054102\n",
      "0.57055926\n",
      "0.6090071\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Thank you for the answer!\"\n",
    "context_user = filter_contexts(user_question)\n",
    "\n",
    "response = chain({\n",
    "    \"first_context\": \"\",\n",
    "    \"input_documents\": context_user,\n",
    "    \"user_input\":  user_question,\n",
    "    \"user_data\": \"\", \"ending_lines\": \"\",\n",
    "    \"chat_history\": convert_to_str(messages)\n",
    "}, return_only_outputs = True)\n",
    "\n",
    "messages.append((\"human\", user_question))\n",
    "messages.append((\"agent\", response['output_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': 'Are you satisfied with my service?\\n[TERMINATE]\\nThank you for calling Amazon!'}"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
